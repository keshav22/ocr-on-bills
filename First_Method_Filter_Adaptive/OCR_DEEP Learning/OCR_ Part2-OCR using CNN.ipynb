{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "HqYb5NXVDdSN"
   },
   "source": [
    "# **Load Libraries**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "SOtEHEKq_hWe"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kesha\\Anaconda3\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import string\n",
    "import os\n",
    "from datetime import datetime as dt\n",
    "\n",
    "import cv2\n",
    "\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "bold = '\\033[1m'\n",
    "end = '\\033[0m'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "mpV8eHhLD3V3"
   },
   "source": [
    "# **Functions**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "EfTGyBIhB0DO"
   },
   "outputs": [],
   "source": [
    "def read_data(file_list):\n",
    "  '''\n",
    "  read data from tfrecords file\n",
    "  '''\n",
    "  file_queue=tf.train.string_input_producer(file_list)\n",
    "  feature = {'images': tf.FixedLenFeature([], tf.string),\n",
    "             'labels': tf.FixedLenFeature([], tf.string)}    \n",
    "  reader = tf.TFRecordReader()  \n",
    "  _,record=reader.read(file_queue)\n",
    "  features = tf.parse_single_example(record, features=feature)\n",
    "  img = tf.decode_raw(features['images'], tf.uint8)\n",
    "  label = tf.decode_raw(features['labels'], tf.uint8)\t\n",
    "  return img,label\n",
    "\n",
    "\n",
    "\n",
    "def minibatch(folder_path, filename, file_count, \n",
    "              image_size, max_char, class_count, \n",
    "              batch_size,):\n",
    "  '''\n",
    "  generate minibatch\n",
    "  '''\n",
    "  file_list = [os.path.join(folder_path, filename + '%d.tfrecords' % i) for i in range(1, file_count+1)]  \n",
    "  img, label = read_data(file_list)\n",
    "  img = tf.cast(tf.reshape(img,img_size), dtype = tf.float32)\n",
    "  label = tf.reshape(label, [1, max_char])\n",
    "  label = tf.one_hot(label,class_count,axis=1)\n",
    "  label = tf.reshape(label,tf.shape(label)[1:])\n",
    "  img_batch,label_batch= tf.train.shuffle_batch([img, label],batch_size,capacity,min_after_dequeue,num_threads=num_of_threads)\n",
    "  return img_batch, tf.cast(label_batch, dtype = tf.int64)\n",
    "\n",
    "\n",
    "\n",
    "def variable(name,shape,initializer,weight_decay = None):\n",
    "  '''\n",
    "  create parameter tensor\n",
    "  '''\n",
    "  var = tf.get_variable(name, shape, initializer = initializer)\n",
    "  if weight_decay is not None:\n",
    "    weight_loss=tf.multiply(tf.nn.l2_loss(var),weight_decay,name=\"weight_loss\")\n",
    "    tf.add_to_collection('losses', weight_loss)\n",
    "  return var\n",
    "\n",
    "\n",
    "\n",
    "def conv_block(block_num,\n",
    "               input_data,\n",
    "               weights, \n",
    "               weight_initializer=tf.contrib.layers.xavier_initializer(),\n",
    "               bias_initializer=tf.constant_initializer(0.0),\n",
    "               conv_op=[1,1,1,1],\n",
    "               conv_padding='SAME',\n",
    "               weight_decay=None,\n",
    "               lrn=True,\n",
    "               dropout=1.0, \n",
    "               activation=True):\n",
    "  '''\n",
    "  convolutional block\n",
    "  '''\n",
    "  with tf.variable_scope('conv'+ str(block_num), reuse = tf.AUTO_REUSE) as scope:\n",
    "    input_data = tf.nn.dropout(input_data, dropout)\n",
    "    kernel = variable('weights', weights, initializer = weight_initializer, weight_decay = weight_decay)\n",
    "    biases = variable('biases', weights[3], initializer=bias_initializer, weight_decay=None)\n",
    "    conv = tf.nn.conv2d(input_data, kernel, conv_op, padding=conv_padding)\n",
    "    pre_activation = tf.nn.bias_add(conv, biases)\n",
    "    if lrn==True:\n",
    "      pre_activation = tf.nn.lrn(pre_activation, 4, bias=1.0, alpha=0.001 / 9.0, beta=0.75,name='norm')\n",
    "    if activation:\n",
    "      conv_out = tf.nn.relu(pre_activation, name=scope.name)\n",
    "      return conv_out\n",
    "    else:\n",
    "      return pre_activation\n",
    "\n",
    "\n",
    "\n",
    "def dense_block(block_num,\n",
    "                input_data,\n",
    "                neurons,\n",
    "                weight_initializer=tf.contrib.layers.xavier_initializer(),\n",
    "                bias_initializer=tf.constant_initializer(0.0),\n",
    "                weight_decay=None,\n",
    "                activation=True, \n",
    "                dropout=1.0):\n",
    "  '''\n",
    "  Fully connected block\n",
    "  '''\n",
    "  with tf.variable_scope('dense'+ str(block_num), reuse = tf.AUTO_REUSE) as scope:\n",
    "    input_data = tf.nn.dropout(input_data, dropout)\n",
    "    weights = variable('weights', [input_data.shape[1], neurons], initializer=weight_initializer, weight_decay = weight_decay)\n",
    "    biases = variable('biases', [1,neurons], initializer = bias_initializer, weight_decay = None)\n",
    "    dense = tf.matmul(input_data,weights)+biases\n",
    "    if activation:\n",
    "      dense=tf.nn.relu(dense, name=scope.name)\n",
    "    return dense\n",
    "  \n",
    "  \n",
    "  \n",
    "def multi_loss(logits, labels, batch_size, max_char):\n",
    "  '''\n",
    "  cross entopy loss for multi class\n",
    "  '''\n",
    "  loss = 0\n",
    "  for i in range(max_char):\n",
    "    loss += tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits\\\n",
    "            (logits=logits[:,i,:],labels=labels[:,:,i]), \\\n",
    "                           name='cross_entropy_loss_mean')\n",
    "  loss /= max_char\n",
    "  tf.add_to_collection('losses', loss)\n",
    "  total_loss=tf.add_n(tf.get_collection('losses'), name='total_loss')\n",
    "  tf.add_to_collection('losses', total_loss)\n",
    "  return total_loss\n",
    "\n",
    "\n",
    "  \n",
    "def parameter_update(loss, learning_rate):\n",
    "  '''\n",
    "  optimization and parameter update using adam optimizer\n",
    "  '''\n",
    "  optimizer=tf.train.AdamOptimizer(learning_rate=learning_rate).minimize(loss)\n",
    "  for var in tf.trainable_variables():\n",
    "    tf.summary.histogram(var.op.name, var)\n",
    "  return optimizer\n",
    "\n",
    "\n",
    "\n",
    "def accuracy_calc(output, label_batch):\n",
    "  '''\n",
    "  calculate accuracy\n",
    "  '''\n",
    "  correct_prediction = tf.equal(tf.cast(tf.argmax(output, 2),dtype=tf.int32),tf.cast(tf.argmax(label_batch, 1),dtype=tf.int32))\n",
    "  accuracy=tf.reduce_mean(tf.cast(correct_prediction,\"float\"))\n",
    "  return accuracy\n",
    "\n",
    "\n",
    "\n",
    "#evaluation\n",
    "def eval(batch_size=1000):\n",
    "\tsteps=((test_data_count))//batch_size\n",
    "\taccu=0\n",
    "\tx_test, y_test = minibatch(folder_path, test_filename, file_count, img_size, max_char, class_count,batch_size)\n",
    "\tlogit_test = inference(x_test, class_count)\n",
    "\taccuracy_test = accuracy_calc(logit_test, y_test)\n",
    "  \n",
    "\tinit=tf.global_variables_initializer()\n",
    "\tsaver=tf.train.Saver()\n",
    "\twith tf.Session() as sess:\n",
    "\t\tsess.run(init)\n",
    "\t\tcoord = tf.train.Coordinator()\n",
    "\t\tthreads = tf.train.start_queue_runners(coord=coord)\n",
    "\t\t#saver.restore(sess,checkpoint_restore)\n",
    "\t\tfor s in range(steps):\n",
    "\t\t\tacc=sess.run(accuracy_test)\n",
    "\t\t\taccu+=acc/steps\n",
    "\t\tprint(\"test set accuracy: \",acc)\n",
    "\n",
    "\t\tcoord.request_stop()\n",
    "\t\tcoord.join(threads)\n",
    "\n",
    "\t\treturn None\n",
    "  \n",
    "  \n",
    "def decoding(encoded_data, type = 'logit'):\n",
    "  if(type == 'logit'):\n",
    "    prediction = np.argmax(encoded_data, 2)\n",
    "  elif(type == 'label'):\n",
    "    prediction = np.argmax(encoded_data, 1)\n",
    "  decoded_prediction = []\n",
    "  for dp in prediction:\n",
    "    predicted_text = ''\n",
    "    for p in dp:\n",
    "      predicted_text += all_chr[p]\n",
    "    decoded_prediction.append(predicted_text)\n",
    "  return decoded_prediction\n",
    "\n",
    "\n",
    "\n",
    "def eval_vizualization(X):\n",
    "  decoded_text = []\n",
    "  logit = inference(X, class_count)\n",
    "  init=tf.global_variables_initializer()\n",
    "  saver=tf.train.Saver()\n",
    "  \n",
    "  with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "    #saver.restore(sess,checkpoint_restore)\n",
    "    text = sess.run(logit)\n",
    "    decoded_text = decoding(text, type = 'logit')\n",
    "  for i in range(X.shape[0]):\n",
    "    x = np.reshape(X[i, :,:,:], img_size[0:2])\n",
    "    plt.imshow(x, cmap = 'gray')\n",
    "    plt.show()\n",
    "    print(\"text: \", decoded_text[i], '<---')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "q1gISaBjD9Yf"
   },
   "source": [
    "# **Model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "Dx4ssU97CMm4"
   },
   "outputs": [],
   "source": [
    "def inference(image_batch, class_count,\n",
    "              dropout=[1,1,1,1],\n",
    "              wd=None):\n",
    "  '''\n",
    "  Forward propagation\n",
    "  '''\n",
    "\n",
    "  i = 0\n",
    "  weights=[[3,3,1,class_count//4],\n",
    "           [3,3,class_count//4,class_count//2],\n",
    "           [3,3,class_count//2,class_count],\n",
    "           [3,3,class_count,class_count]]\n",
    "  conv_op=[[1,1,1,1],[1,1,1,1],[1,1,1,1], [1,1,1,1]]\n",
    "  \n",
    "  conv1 = conv_block(1,image_batch,weights[i], conv_op = conv_op[i], conv_padding='SAME', dropout=dropout[i],weight_decay=wd)\n",
    "  i=i+1\n",
    "  pool1=tf.nn.max_pool(conv1, ksize=[1, 2, 2, 1], strides=[1,2,2,1],padding='VALID', name='pool1') #16x128\n",
    "  \n",
    "  conv2 = conv_block(2,pool1,weights[i], conv_op = conv_op[i], conv_padding='SAME', dropout=dropout[i],weight_decay=wd)\n",
    "  i=i+1\n",
    "  pool2=tf.nn.max_pool(conv2, ksize=[1, 2, 2, 1], strides=[1,2,2,1],padding='VALID', name='pool2') #8x64\n",
    "  \n",
    "  conv3 = conv_block(3,pool2,weights[i], conv_op = conv_op[i], conv_padding='SAME', dropout=dropout[i],weight_decay=wd)\n",
    "  i=i+1\n",
    "  pool3=tf.nn.max_pool(conv3, ksize=[1, 2, 2, 1], strides=[1,2,2,1],padding='VALID', name='pool3') #4x32\n",
    "  \n",
    "  conv4 = conv_block(4,pool3,weights[i], conv_op = conv_op[i], conv_padding='SAME', dropout=dropout[i],weight_decay=wd)\n",
    "  pool4=tf.nn.max_pool(conv4, ksize=[1, 4, 2, 1], strides=[1,1,2,1],padding='VALID', name='pool4') #1x16\n",
    "  \n",
    "  flat=tf.reshape(pool4, [tf.shape(image_batch)[0],max_char, class_count], name='flat')\n",
    "\t\t\n",
    "  return flat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "49g9QIAXEBWj"
   },
   "source": [
    "# **Train**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "VVGIHADUCVJD"
   },
   "outputs": [],
   "source": [
    "def train(folder_path, train_filename, test_filename, \n",
    "          data_per_train_file, test_data_count, file_count,\n",
    "          weights, dropout, wd,\n",
    "          img_size, max_char, class_count, \n",
    "          batch_size = 32, learning_rate=0.01, epochs=5, \n",
    "          restore=False, var_lr = [None,None]):\n",
    "  \n",
    "\ttrain_step = train_data_count//batch_size\n",
    "\ttest_step = test_data_count//batch_size\n",
    "  \n",
    "  #build graph\n",
    "\twith tf.Graph().as_default():\n",
    "\t\tx_train, y_train = minibatch(folder_path, train_filename, file_count, img_size, max_char, class_count,batch_size)     \n",
    "\t\tlogit_train = inference(x_train, class_count, dropout = dropout, wd = wd)\n",
    "\t\tcost = multi_loss(logit_train, y_train, batch_size, max_char)\n",
    "\t\tupdate=parameter_update(cost,learning_rate)\t\n",
    "\t\taccuracy_train = accuracy_calc(logit_train, y_train)\n",
    "    \n",
    "\t\tx_test, y_test = minibatch(folder_path, test_filename, file_count, img_size, max_char, class_count,batch_size)\n",
    "\t\tlogit_test = inference(x_test, class_count)\n",
    "\t\taccuracy_test = accuracy_calc(logit_test, y_test)\n",
    "    \n",
    "\t\tsaver = tf.train.Saver()\n",
    "    \n",
    "    #start session\n",
    "\t\twith tf.Session() as sess:\n",
    "      #initialize the variables\n",
    "\t\t\tsess.run(tf.global_variables_initializer())\n",
    "\t\t\tsess.run(tf.local_variables_initializer())\n",
    "\t\t\tcoord = tf.train.Coordinator()\n",
    "\t\t\tthreads = tf.train.start_queue_runners(coord=coord) \n",
    "      \n",
    "      #restore the variables\n",
    "\t\t\tif restore == True:\n",
    "\t\t\t\tloader = tf.train.import_meta_graph(checkpoint_restore +'.meta')\n",
    "\t\t\t\tloader.restore(sess, checkpoint_restore)\n",
    "        \n",
    "\t\t\t#train for given number of epochs\n",
    "\t\t\tfor e in range(epochs): \n",
    "\t\t\t\tprint(bold + \"\\nepoch:\" + end, e)\n",
    "\t\t\t\ttrain_epoch_cost = 0\n",
    "\t\t\t\ttrain_epoch_acc = 0\n",
    "\t\t\t\ttest_epoch_acc = 0\n",
    "        \n",
    "        #train for given number of steps in one epoch\n",
    "\t\t\t\tfor s in range(train_step):\n",
    "\t\t\t\t\t_,train_batch_cost = sess.run([update, cost])\t          \n",
    "\t\t\t\t\tif s % (train_step//20) == 0 and s != 0:\n",
    "\t\t\t\t\t\tprint('~', end = '')\n",
    "\t\t\t\t\telif(s == (train_step) - 1):\n",
    "\t\t\t\t\t\tprint('')            \n",
    "\t\t\t\t\ttrain_epoch_cost += train_batch_cost/(train_step)\t          \n",
    "\t\t\t\tprint(bold + \"epoch_cost: \" + end,train_epoch_cost)\n",
    "        \n",
    "        #calculate accuracy of training set\n",
    "\t\t\t\tfor i in range(train_step//5):\n",
    "\t\t\t\t\ttrain_epoch_acc = sess.run(accuracy_train)\n",
    "\t\t\t\t\ttrain_epoch_acc += train_epoch_acc/(train_step)        \n",
    "\t\t\t\tprint(bold + \"train epoch accuracy: \" + end,train_epoch_acc, \"\\n\")\n",
    "        \n",
    "        #calculate accuracy of test set\n",
    "\t\t\t\tfor i in range(test_step):\n",
    "\t\t\t\t\ttest_epoch_acc = sess.run(accuracy_test)\n",
    "\t\t\t\t\ttest_epoch_acc += test_epoch_acc/test_step    \n",
    "\t\t\t\tprint(bold + \"test epoch accuracy: \" + end, test_epoch_acc, \"\\n\")\n",
    "        \n",
    "        #afer every 20 epoch decrease learning rate by factor of 10\n",
    "\t\t\t\tif var_lr[0] != None:\n",
    "\t\t\t\t\tif e%var_lr[0] == 0:\n",
    "\t\t\t\t\t\tlearning_rate = learning_rate/var_lr[1]\n",
    "      \n",
    "      #save all the variables\n",
    "\t\t\tsave_path = saver.save(sess, checkpoint_save)\t\n",
    "\t\t\tcoord.request_stop()\n",
    "\t\t\tcoord.join(threads)\n",
    "\t\t\t\n",
    "\treturn None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "y6J1kZAECcXE"
   },
   "outputs": [],
   "source": [
    "folder_path = \"./tfrecordoutput/\"\n",
    "file_count = 2\n",
    "train_data_count = 8192 * file_count\n",
    "test_data_count = 2048 * file_count\n",
    "img_size = [32,256,1]\n",
    "class_count = 63\n",
    "max_char = 16\n",
    "keyword = '3to8'\n",
    "train_filename = 'train_' + keyword + '_'\n",
    "test_filename = 'test_' + keyword + '_'\n",
    "checkpoint_restore = \"checkpoint_3to8.ckpt\"\n",
    "checkpoint_save = \"checkpoint_3to8.ckpt\"\n",
    "\n",
    "dropout = [1, 1, 1, 1]\n",
    "wd = 0.000\n",
    "lr = 0.01\n",
    "batch_size = 32\n",
    "epochs = 5\n",
    "\n",
    "num_of_threads=16\n",
    "min_after_dequeue=5000\n",
    "capacity=min_after_dequeue+(num_of_threads+1)*batch_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 714
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 434949,
     "status": "ok",
     "timestamp": 1532018515949,
     "user": {
      "displayName": "Vijendra Singh",
      "photoUrl": "//lh3.googleusercontent.com/-NdZ5dixuTHU/AAAAAAAAAAI/AAAAAAAArI4/R6qZstWMpR4/s50-c-k-no/photo.jpg",
      "userId": "111198229299491674196"
     },
     "user_tz": -330
    },
    "id": "uXtfaRdjDOBK",
    "outputId": "21d63f3b-80dd-4ed2-d51a-cd5e63e2cbfe",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-2-a2b9923b4798>:104: softmax_cross_entropy_with_logits (from tensorflow.python.ops.nn_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "\n",
      "Future major versions of TensorFlow will allow gradients to flow\n",
      "into the labels input on backprop by default.\n",
      "\n",
      "See @{tf.nn.softmax_cross_entropy_with_logits_v2}.\n",
      "\n",
      "\u001b[1m\n",
      "epoch:\u001b[0m 0\n",
      "~~~~~~~~~~~~~~~~~~~~\n",
      "\u001b[1mepoch_cost: \u001b[0m 1.2440493390895426\n",
      "\u001b[1mtrain epoch accuracy: \u001b[0m 0.8473548889160156 \n",
      "\n",
      "\u001b[1mtest epoch accuracy: \u001b[0m 0.84246826171875 \n",
      "\n",
      "\u001b[1m\n",
      "epoch:\u001b[0m 1\n",
      "~~~~~~~~~~~~~~~~~~~~\n",
      "\u001b[1mepoch_cost: \u001b[0m 0.668015128467232\n",
      "\u001b[1mtrain epoch accuracy: \u001b[0m 0.8512687683105469 \n",
      "\n",
      "\u001b[1mtest epoch accuracy: \u001b[0m 0.8345947265625 \n",
      "\n",
      "\u001b[1m\n",
      "epoch:\u001b[0m 2\n",
      "~~~~~~~~~~~~~~~~~~~~\n",
      "\u001b[1mepoch_cost: \u001b[0m 0.5868764946353622\n",
      "\u001b[1mtrain epoch accuracy: \u001b[0m 0.8532257080078125 \n",
      "\n",
      "\u001b[1mtest epoch accuracy: \u001b[0m 0.8523101806640625 \n",
      "\n",
      "\u001b[1m\n",
      "epoch:\u001b[0m 3\n",
      "~~~~~~~~~~~~~~~~~~~~\n",
      "\u001b[1mepoch_cost: \u001b[0m 0.5572655341820791\n",
      "\u001b[1mtrain epoch accuracy: \u001b[0m 0.8806228637695312 \n",
      "\n",
      "\u001b[1mtest epoch accuracy: \u001b[0m 0.9113616943359375 \n",
      "\n",
      "\u001b[1m\n",
      "epoch:\u001b[0m 4\n",
      "~~~~~~~~~~~~~~~~~~~~\n",
      "\u001b[1mepoch_cost: \u001b[0m 0.5260253489250317\n",
      "\u001b[1mtrain epoch accuracy: \u001b[0m 0.8786659240722656 \n",
      "\n",
      "\u001b[1mtest epoch accuracy: \u001b[0m 0.9271087646484375 \n",
      "\n",
      "INFO:tensorflow:Error reported to Coordinator: <class 'tensorflow.python.framework.errors_impl.CancelledError'>, Enqueue operation was cancelled\n",
      "\t [[Node: shuffle_batch/random_shuffle_queue_enqueue = QueueEnqueueV2[Tcomponents=[DT_FLOAT, DT_FLOAT], timeout_ms=-1, _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"](shuffle_batch/random_shuffle_queue, Cast, Reshape_2)]]\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Parent directory of checkpoint_3to8.ckpt doesn't exist, can't save.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNotFoundError\u001b[0m                             Traceback (most recent call last)",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_call\u001b[1;34m(self, fn, *args)\u001b[0m\n\u001b[0;32m   1321\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1322\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1323\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[1;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[0;32m   1306\u001b[0m       return self._call_tf_sessionrun(\n\u001b[1;32m-> 1307\u001b[1;33m           options, feed_dict, fetch_list, target_list, run_metadata)\n\u001b[0m\u001b[0;32m   1308\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_call_tf_sessionrun\u001b[1;34m(self, options, feed_dict, fetch_list, target_list, run_metadata)\u001b[0m\n\u001b[0;32m   1408\u001b[0m           \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1409\u001b[1;33m           run_metadata)\n\u001b[0m\u001b[0;32m   1410\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNotFoundError\u001b[0m: Failed to create a directory: ; No such file or directory\n\t [[Node: save/SaveV2 = SaveV2[dtypes=[DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, ..., DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT], _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"](_arg_save/Const_0_0, save/SaveV2/tensor_names, save/SaveV2/shape_and_slices, beta1_power, beta2_power, conv1/biases, conv1/biases/Adam, conv1/biases/Adam_1, conv1/weights, conv1/weights/Adam, conv1/weights/Adam_1, conv2/biases, conv2/biases/Adam, conv2/biases/Adam_1, conv2/weights, conv2/weights/Adam, conv2/weights/Adam_1, conv3/biases, conv3/biases/Adam, conv3/biases/Adam_1, conv3/weights, conv3/weights/Adam, conv3/weights/Adam_1, conv4/biases, conv4/biases/Adam, conv4/biases/Adam_1, conv4/weights, conv4/weights/Adam, conv4/weights/Adam_1)]]",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mNotFoundError\u001b[0m                             Traceback (most recent call last)",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\training\\saver.py\u001b[0m in \u001b[0;36msave\u001b[1;34m(self, sess, save_path, global_step, latest_filename, meta_graph_suffix, write_meta_graph, write_state, strip_default_attrs)\u001b[0m\n\u001b[0;32m   1702\u001b[0m               \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msaver_def\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msave_tensor_name\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1703\u001b[1;33m               {self.saver_def.filename_tensor_name: checkpoint_file})\n\u001b[0m\u001b[0;32m   1704\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36mrun\u001b[1;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m    899\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[1;32m--> 900\u001b[1;33m                          run_metadata_ptr)\n\u001b[0m\u001b[0;32m    901\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run\u001b[1;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1134\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[1;32m-> 1135\u001b[1;33m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[0;32m   1136\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_run\u001b[1;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1315\u001b[0m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[1;32m-> 1316\u001b[1;33m                            run_metadata)\n\u001b[0m\u001b[0;32m   1317\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_call\u001b[1;34m(self, fn, *args)\u001b[0m\n\u001b[0;32m   1334\u001b[0m           \u001b[1;32mpass\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1335\u001b[1;33m       \u001b[1;32mraise\u001b[0m \u001b[0mtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnode_def\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mop\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1336\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNotFoundError\u001b[0m: Failed to create a directory: ; No such file or directory\n\t [[Node: save/SaveV2 = SaveV2[dtypes=[DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, ..., DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT], _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"](_arg_save/Const_0_0, save/SaveV2/tensor_names, save/SaveV2/shape_and_slices, beta1_power, beta2_power, conv1/biases, conv1/biases/Adam, conv1/biases/Adam_1, conv1/weights, conv1/weights/Adam, conv1/weights/Adam_1, conv2/biases, conv2/biases/Adam, conv2/biases/Adam_1, conv2/weights, conv2/weights/Adam, conv2/weights/Adam_1, conv3/biases, conv3/biases/Adam, conv3/biases/Adam_1, conv3/weights, conv3/weights/Adam, conv3/weights/Adam_1, conv4/biases, conv4/biases/Adam, conv4/biases/Adam_1, conv4/weights, conv4/weights/Adam, conv4/weights/Adam_1)]]\n\nCaused by op 'save/SaveV2', defined at:\n  File \"C:\\Users\\kesha\\Anaconda3\\lib\\runpy.py\", line 193, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"C:\\Users\\kesha\\Anaconda3\\lib\\runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"C:\\Users\\kesha\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py\", line 16, in <module>\n    app.launch_new_instance()\n  File \"C:\\Users\\kesha\\Anaconda3\\lib\\site-packages\\traitlets\\config\\application.py\", line 658, in launch_instance\n    app.start()\n  File \"C:\\Users\\kesha\\Anaconda3\\lib\\site-packages\\ipykernel\\kernelapp.py\", line 486, in start\n    self.io_loop.start()\n  File \"C:\\Users\\kesha\\Anaconda3\\lib\\site-packages\\zmq\\eventloop\\ioloop.py\", line 177, in start\n    super(ZMQIOLoop, self).start()\n  File \"C:\\Users\\kesha\\Anaconda3\\lib\\site-packages\\tornado\\ioloop.py\", line 888, in start\n    handler_func(fd_obj, events)\n  File \"C:\\Users\\kesha\\Anaconda3\\lib\\site-packages\\tornado\\stack_context.py\", line 277, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"C:\\Users\\kesha\\Anaconda3\\lib\\site-packages\\zmq\\eventloop\\zmqstream.py\", line 440, in _handle_events\n    self._handle_recv()\n  File \"C:\\Users\\kesha\\Anaconda3\\lib\\site-packages\\zmq\\eventloop\\zmqstream.py\", line 472, in _handle_recv\n    self._run_callback(callback, msg)\n  File \"C:\\Users\\kesha\\Anaconda3\\lib\\site-packages\\zmq\\eventloop\\zmqstream.py\", line 414, in _run_callback\n    callback(*args, **kwargs)\n  File \"C:\\Users\\kesha\\Anaconda3\\lib\\site-packages\\tornado\\stack_context.py\", line 277, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"C:\\Users\\kesha\\Anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 283, in dispatcher\n    return self.dispatch_shell(stream, msg)\n  File \"C:\\Users\\kesha\\Anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 233, in dispatch_shell\n    handler(stream, idents, msg)\n  File \"C:\\Users\\kesha\\Anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 399, in execute_request\n    user_expressions, allow_stdin)\n  File \"C:\\Users\\kesha\\Anaconda3\\lib\\site-packages\\ipykernel\\ipkernel.py\", line 208, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"C:\\Users\\kesha\\Anaconda3\\lib\\site-packages\\ipykernel\\zmqshell.py\", line 537, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"C:\\Users\\kesha\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2728, in run_cell\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"C:\\Users\\kesha\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2856, in run_ast_nodes\n    if self.run_code(code, result):\n  File \"C:\\Users\\kesha\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2910, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-7-490afb6a1edb>\", line 6, in <module>\n    restore=False, var_lr=[None,None])\n  File \"<ipython-input-5-a61447ca5d7f>\", line 23, in train\n    saver = tf.train.Saver()\n  File \"C:\\Users\\kesha\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\training\\saver.py\", line 1338, in __init__\n    self.build()\n  File \"C:\\Users\\kesha\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\training\\saver.py\", line 1347, in build\n    self._build(self._filename, build_save=True, build_restore=True)\n  File \"C:\\Users\\kesha\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\training\\saver.py\", line 1384, in _build\n    build_save=build_save, build_restore=build_restore)\n  File \"C:\\Users\\kesha\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\training\\saver.py\", line 832, in _build_internal\n    save_tensor = self._AddSaveOps(filename_tensor, saveables)\n  File \"C:\\Users\\kesha\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\training\\saver.py\", line 350, in _AddSaveOps\n    save = self.save_op(filename_tensor, saveables)\n  File \"C:\\Users\\kesha\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\training\\saver.py\", line 266, in save_op\n    tensors)\n  File \"C:\\Users\\kesha\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\gen_io_ops.py\", line 1800, in save_v2\n    shape_and_slices=shape_and_slices, tensors=tensors, name=name)\n  File \"C:\\Users\\kesha\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py\", line 787, in _apply_op_helper\n    op_def=op_def)\n  File \"C:\\Users\\kesha\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 3392, in create_op\n    op_def=op_def)\n  File \"C:\\Users\\kesha\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 1718, in __init__\n    self._traceback = self._graph._extract_stack()  # pylint: disable=protected-access\n\nNotFoundError (see above for traceback): Failed to create a directory: ; No such file or directory\n\t [[Node: save/SaveV2 = SaveV2[dtypes=[DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, ..., DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT], _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"](_arg_save/Const_0_0, save/SaveV2/tensor_names, save/SaveV2/shape_and_slices, beta1_power, beta2_power, conv1/biases, conv1/biases/Adam, conv1/biases/Adam_1, conv1/weights, conv1/weights/Adam, conv1/weights/Adam_1, conv2/biases, conv2/biases/Adam, conv2/biases/Adam_1, conv2/weights, conv2/weights/Adam, conv2/weights/Adam_1, conv3/biases, conv3/biases/Adam, conv3/biases/Adam_1, conv3/weights, conv3/weights/Adam, conv3/weights/Adam_1, conv4/biases, conv4/biases/Adam, conv4/biases/Adam_1, conv4/weights, conv4/weights/Adam, conv4/weights/Adam_1)]]\n",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-7-490afb6a1edb>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      4\u001b[0m       \u001b[0mimg_size\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmax_char\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mclass_count\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m       \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlearning_rate\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mepochs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m       restore=False, var_lr=[None,None])\n\u001b[0m",
      "\u001b[1;32m<ipython-input-5-a61447ca5d7f>\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(folder_path, train_filename, test_filename, data_per_train_file, test_data_count, file_count, weights, dropout, wd, img_size, max_char, class_count, batch_size, learning_rate, epochs, restore, var_lr)\u001b[0m\n\u001b[0;32m     71\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     72\u001b[0m       \u001b[1;31m#save all the variables\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 73\u001b[1;33m                         \u001b[0msave_path\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msaver\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msave\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msess\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcheckpoint_save\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     74\u001b[0m                         \u001b[0mcoord\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrequest_stop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     75\u001b[0m                         \u001b[0mcoord\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mthreads\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\training\\saver.py\u001b[0m in \u001b[0;36msave\u001b[1;34m(self, sess, save_path, global_step, latest_filename, meta_graph_suffix, write_meta_graph, write_state, strip_default_attrs)\u001b[0m\n\u001b[0;32m   1718\u001b[0m               \"Parent directory of {} doesn't exist, can't save.\".format(\n\u001b[0;32m   1719\u001b[0m                   save_path))\n\u001b[1;32m-> 1720\u001b[1;33m         \u001b[1;32mraise\u001b[0m \u001b[0mexc\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1721\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1722\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mwrite_meta_graph\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Parent directory of checkpoint_3to8.ckpt doesn't exist, can't save."
     ]
    }
   ],
   "source": [
    "train(folder_path, train_filename, test_filename, \n",
    "      train_data_count, test_data_count, file_count,\n",
    "      class_count, dropout, wd,\n",
    "      img_size, max_char, class_count, \n",
    "      batch_size=batch_size, learning_rate=lr, epochs=epochs, \n",
    "      restore=False, var_lr=[None,None])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "GcsdqO1cElm3"
   },
   "source": [
    "# **Evaluate**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "zjvFGVgnWO7H"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test set accuracy:  0.0055\n"
     ]
    }
   ],
   "source": [
    "eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 462
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 52902,
     "status": "ok",
     "timestamp": 1532017545919,
     "user": {
      "displayName": "Vijendra Singh",
      "photoUrl": "//lh3.googleusercontent.com/-NdZ5dixuTHU/AAAAAAAAAAI/AAAAAAAArI4/R6qZstWMpR4/s50-c-k-no/photo.jpg",
      "userId": "111198229299491674196"
     },
     "user_tz": -330
    },
    "id": "afLrhQHKDPcw",
    "outputId": "419dbe6c-ed4b-4e89-d48e-47f8355be6f1"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "text:  22Kjaaaaaaaaaaaa <---\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "text:  222222Aaaaaaaaaa <---\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAABMCAYAAAB9PUwnAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMi4zLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvIxREBQAAC5FJREFUeJzt3X+MVOW9x/H3dxhgXXcJ7J0LIjULFDF3EyM/tEW7lmLhVkh0qbHRm9gKIcE/Wm2NNxbbRKvxj7ZJa2KsGBQNNeSaRmhYQ5rSKGj8Q2D3sl2FlQp1d2VZwQ2wUBVmd+bbP+bMuLO7ww67szPs2c8reTIzzzxnzvc8PPvlzHPOnGPujoiIjH2RUgcgIiKFoYQuIhISSugiIiGhhC4iEhJK6CIiIaGELiISEiNK6GZ2u5kdNrMjZrahUEGJiMils+Geh25mE4B/ACuAY8B+4H/c/VDhwhMRkXyNZA/9G8ARd/+nu8eB14C6woQlIiKXKjqCZWcBn/R5fQz45sUWMDP9LFVE5NJ1uft/DtVoJAndBqkbkLDNbD2wfgTrEREZ79ryaTSShH4MuKbP668Bx/s3cvdNwCbQHrqIyGgayRz6fuBaM5tjZpOAe4H6woQlIiKXath76O7ea2Y/Af4KTABedveDBYtMREQuybBPWxzWyjTlIiIyHI3ufuNQjfRLURGRkFBCFxEJCSV0EZGQGMlpiyNSVlZGWVnZkO16e3v54osvAEgmkzk/CyAajRKNpjbp7NmzF11m0qRJANTU1LBs2TLi8TgAO3fupL29PedyIiKXLXcvWkmt7tIdOHDADxw44BUVFU7qx0uZsmbNGo/H4x6Px7OW6ejo8I6ODl+wYMGAZSKRiK9du9bXrl3rn3/+uSeTyUw5dOiQ19bWDlhGRUVFpYSlIZ8cqykXEZGwKOYe+uLFi4e1h562fft2r6io8KqqKq+qqvKPP/44r+V27drlZWVlXlZW5oCXlZV5a2urt7a2Dtr+ySefLPX/xioqKip9S1576EWdQ29sbBzWcl1dXQC88sor1NXV8fjjjwMwe/bsvJZfsWIF27ZtA+CRRx7hzJkz7Nu3D4Dq6uqstolEgg8//JBoNEpvb++w4hURKYWiHxQ1S13Ta9myZdTW1rJ69WoAFi1aBEBnZyebN28GUgcuKyoqOHQodYn15uZmduzYwfz587M+M5FIANDS0kJrayvV1dVcf/31WW1WrVoFwGeffcaaNWvYsCF1P44ZM2Zwyy230NPTA8Czzz7Ljh07lMxFZMzRHLqISFjkMy9TqMIgc0MbN270jRs3Zuav33vvPS8vL/fy8vJMm2g06tFo1JcvX+4XLlzImu8+f/68L1261JcuXZpp3/cslkQikdW+u7s768yXaDTqkUgks45IJFLquTIVFRWV/uXym0MfrvT0x4oVKzLnjwO4O1u2bGHv3r1Z7ZPJZGbO/KGHHmLBggWZ96688krmzJlDU1MTAFOnTuX111/nk09S9+p44IEHMue9i4iMJWMioU+dOhWAW2+9Nav+9OnTPPbYY5w/f37AMukfFj388MPs2rWLiRMnAjBhwgRWr16dOSja0NDAVVddlVmupqaGm2++OfNDIxGRsUJz6CIiITEmEnosFiMWi3HTTTdl1Z86dYpTp05ddNmGhoYBZ6zceeedVFZWUllZSWdnZ9Z7R48epby8vDCBi4gU0ZhI6F1dXXR1ddHWln1bvTfeeGPIZePxOM3NzVl177zzDu3t7bS3tw9of+7cOc6cOTOygEVESmBMJPRcvvzyy2G1i0S+2uz+c+WaOxeRsWpMJ3QREfnKkAndzK4xs91m1mJmB83sp0F9lZn9zcw+Ch6njVaQ1dXVVFdXM3369Kz6lStXZp3GOJgpU6ZknbYIcMMNN1BVVUVVVVXBYxURKZV89tB7gUfc/b+AJcCPzawG2AC86e7XAm8Gr0dFIpEgkUgMmDqZNWvWkAcw58+fzxVXXJFV193dnXXtdBGRMBgyo7l7J9AZPD9nZi3ALKAO+E7QbAuwB/j5aASZvpbL7t27ueeeezL1sViM++67j+eeew5IXftl69atLF68OHM9mIULFzJ58uSsz3vppZc4efLkaIQqIlIyl7SLamazgYXAXmBGkOxx904zm55jmfXA+pGFKSIiQ8k7oZtZBbAN+Jm7n01fNXEo7r4J2BR8hg8nyLR33303aw89EonwxBNPUF9fD8AzzzzDXXfdBcDTTz8NkLmKYtqFCxcyP/sXEQmTvM5yMbOJpJL5VnffHlSfMLOZwfszgVGbw0gmkySTSV544QU+/fTTrPdisRhNTU00NTVlft7fV/+6/fv38/bbb49WqCIiJZPPWS4GbAZa3P33fd6qB+4Pnt8P7BhOAP0PTl7sxtG9vb089dRTA+qnTZvGtGnTuOOOO3Iu293dTXd3Nw8++GBWff/16UCpiIxV+WSvbwE/BN43s/RcxS+AXwN/MrN1QDvwg+EEUFtbm/V67ty5mSQ72FUPX3zxRQ4ePAjAzp07qaioyGs96XbLly+no6Mjc1OMuXPnXjQeEZGxIp+zXN4Fck2Yf7ew4YiIyLCV8gYXkUgkc8Pnt956y9va2vy6667L3Gyif/t0Sd/w+e677/ZXX33VE4nEgBtZ9PT0eE9Pj/d34sQJX7JkSWYd8+bN87a2Nt+zZ4/v2bPHY7GYbnKhoqJyuZW8bnBhQaItisHOcklfVyUSiZBMJolEIpd0P89IJMK8efOA1LTKlClTiMfjHD9+HIB169bx6KOPcvr0aQCef/556uvrM2e6RKPRzHrhqwOwIiKXkUZ3v3GoRiVP6KPt6quv5rbbbqOyshKAffv20djYWOwwRERGIq+ErotziYiEROj30EVEQkB76CIi44kSuohISCihi4iEhBK6iEhIFPvCJf8CDhd5nZejGNBV6iBKTH2Qon5QH8DQfVCdz4cUO6EfzudIbdiZWcN47wf1QYr6QX0AhesDTbmIiISEErqISEgUO6FvKvL6LlfqB/VBmvpBfQAF6oOi/lJURERGj6ZcRERCQgldRCQkipbQzex2MztsZkfMbEOx1ltqZtZqZu+bWZOZNQR1VWb2NzP7KHicVuo4C83MXjazk2b2QZ+6QbfbUp4NxkazmS0qXeSFk6MPfmVmHcF4aDKzVX3eeyzog8Nm9r3SRF1YZnaNme02sxYzO2hmPw3qx9tYyNUPhR0PRbpT0QTgKDAXmAT8Hagp5t2SSlWAViDWr+63wIbg+QbgN6WOcxS2+9vAIuCDobYbWAX8hdStDpcAe0sd/yj2wa+A/x2kbU3wdzEZmBP8vUwo9TYUoA9mAouC55XAP4JtHW9jIVc/FHQ8FGsP/RvAEXf/p7vHgdeAuiKt+3JUB2wJnm8BVpcwllHh7u8Ap/pV59ruOuCPnvIeMNXMZhYn0tGTow9yqQNec/cL7v4xcITU382Y5u6d7v7/wfNzQAswi/E3FnL1Qy7DGg/FSuizgE/6vD7GxTcmTBzYZWaNZrY+qJvh7p2Q+ocGppcsuuLKtd3jbXz8JJhOeLnPdFvo+8DMZgMLgb2M47HQrx+ggOOhWAndBqkbL+dLfsvdFwErgR+b2bdLHdBlaDyNj43A14EFQCfwu6A+1H1gZhXANuBn7n72Yk0HqQtzPxR0PBQroR8Drunz+mvA8SKtu6Tc/XjweBL4M6mvTSfSXyODx5Oli7Cocm33uBkf7n7C3RPungRe5Kuv0aHtAzObSCqJbXX37UH1uBsLg/VDocdDsRL6fuBaM5tjZpOAe4H6Iq27ZMzsSjOrTD8H/hv4gNS23x80ux/YUZoIiy7XdtcDPwrOcFgCdKe/jodNv/ng75MaD5Dqg3vNbLKZzQGuBfYVO75CMzMDNgMt7v77Pm+Nq7GQqx8KPh6KeJR3Fakju0eBX5b6qHORtnkuqSPVfwcOprcb+A/gTeCj4LGq1LGOwrb/H6mvkD2k9jbW5dpuUl8v/xCMjfeBG0sd/yj2wavBNjYHf7Qz+7T/ZdAHh4GVpY6/QH1QS2qqoBloCsqqcTgWcvVDQceDfvovIhIS+qWoiEhIKKGLiISEErqISEgooYuIhIQSuohISCihi4iEhBK6iEhI/Bs/ibTOlnZWrQAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "text:  22Kraaaaaaaaaaaa <---\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "text:  K22Aaaaaaaaaaaaa <---\n"
     ]
    }
   ],
   "source": [
    "all_chr = list(string.ascii_letters) + list(string.digits) + list(' ')\n",
    "x_check, y_check=minibatch(folder_path, train_filename, file_count, img_size, max_char, class_count,batch_size) \n",
    "saver = tf.train.Saver()\n",
    "\n",
    "with tf.Session() as sess:\n",
    "  sess.run(tf.global_variables_initializer())\n",
    "  sess.run(tf.local_variables_initializer())\n",
    "  coord = tf.train.Coordinator()\n",
    "  threads = tf.train.start_queue_runners(coord=coord) \n",
    "  \n",
    "  x_c = sess.run(x_check)  \n",
    "  eval_vizualization(x_c[1:5])\n",
    "  \n",
    "  coord.request_stop()\n",
    "  coord.join(threads)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "Zq-1-sdKEruW"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "default_view": {},
   "name": "OCR using CNN.ipynb",
   "provenance": [],
   "version": "0.3.2",
   "views": {}
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
